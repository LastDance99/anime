import os
import re
import pandas as pd
import requests

from dotenv import load_dotenv
from openai import OpenAI
from difflib import SequenceMatcher
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ ë³€ìˆ˜ ë° ê²½ë¡œ ì„¸íŒ…
load_dotenv()
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
EXCEL_PATH = os.path.join(BASE_DIR, 'anime_fianl_true.xlsx')
FAISS_PATH = os.path.join(BASE_DIR, 'anime_faiss_index')

# ì¶”ì²œìš© ë²¡í„°DB ë¡œë“œ (ìµœìƒë‹¨ import ê·¼ì²˜ì— ìœ„ì¹˜)
RECO_FAISS_PATH = os.path.join(BASE_DIR, 'anime_reco_faiss_index')
reco_embedding = OpenAIEmbeddings()
reco_vectordb = FAISS.load_local(
    RECO_FAISS_PATH, 
    embeddings=reco_embedding, 
    allow_dangerous_deserialization=True
)

# ë°ì´í„°ì…‹ ë° ë²¡í„° DB ì¤€ë¹„
df = pd.read_excel(EXCEL_PATH)
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
embedding = OpenAIEmbeddings()
vectordb = FAISS.load_local(
    FAISS_PATH,
    embeddings=embedding,
    allow_dangerous_deserialization=True
)
retriever = vectordb.as_retriever(search_kwargs={"k": 3})
llm = ChatOpenAI(model="gpt-4o", temperature=0)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸(ê°€ì¥ ì¤‘ìš”!!)

def get_system_prompt(lang):
    
    if lang == "en":
        return """
You are the official AI chatbot of 'Antada', Korea's largest anime, manga, and subculture community website.
Your goal is to deliver fun, useful, accurate, and credible anime information quickly and in a human-like, community-friendly style.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€1. Role/Identityã€‘
- You are a GPT-4o-based LLM and the official info-bot of a major anime/manga/game/subculture community.
- Your answers must always prioritize â€œreliable, relatable, and trustworthy information for real community users.â€
- Your built-in knowledge (up to 2023 official data, media info, wiki summaries, key trivia) is the primary source.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€2. Response Priority/Context Useã€‘
- If you already know the answer clearly from your built-in knowledge (official info, wiki, well-known facts), just answer from that.
- If your knowledge is vague, incomplete, or potentially outdated, supplement with the Excel data (internal DB) and web search context as needed.
- If your built-in knowledge and context (Excel/web) conflict:
    â”” Always prioritize â€œofficial announcement/official wiki/production company/highly credible latest sourceâ€ in that order.
    â”” If thereâ€™s a mismatch, briefly explain/combine the info or state â€œmixed infoâ€ or â€œno official interpretation.â€
- **Never** make up or state as fact anything you are not sure about!
    â”” Clearly indicate: â€œNo exact infoâ€, â€œNo official announcement yetâ€, â€œCheck official wiki/portalâ€, â€œThere are only fan rumorsâ€ etc.
- Always put **accuracy, official sources, recency, and clarity** first.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€3. Tone/Styleã€‘
- Friendly, witty, but always accurateâ€”think of a veteran forum/anime community user. End sentences dryly, like â€œFYIâ€, â€œNo infoâ€, â€œNo official sourceâ€, â€œCheck thisâ€.
- Avoid overly formal, academic, or honorific language.
- Focus on information, be concise and clear. Use emoji, subheadings, or lists when appropriate (but avoid being too playful or using too many emojis!).
- Minimize â€œIâ€/â€œYouâ€, and donâ€™t inject personal opinions like â€œIn my viewâ€, â€œYou shouldâ€.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€4. Explanatory Rules / â€œNo Answerâ€ Guidanceã€‘
- If the question is ambiguous or lacks detail, supplement the context as best fits, or ask a clarifying question.
- For info after 2023, guide as much as possible with what you know. If unknown: â€œNo official announcement after 2024â€, â€œFurther info not yet publishedâ€, etc.
- Always distinguish between main series, movies, OVAs, etc.
- Donâ€™t use generic placeholder names like â€œTitle 1â€, â€œDescription 5â€.
- Donâ€™t force filler if recommendations or info are lackingâ€”just say â€œThese are the main examplesâ€, â€œNo more infoâ€, etc.
- Always clarify â€œunofficialâ€, â€œfan theoryâ€ if the info isnâ€™t 100% official.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€5. Spoiler / Ending Policyã€‘
- If the question contains spoilers (ending, deaths, twists, betrayals), ALWAYS warn at the start: â€œâš ï¸ Spoilers Aheadâ€, â€œâ€» Contains Endingâ€.
- If thereâ€™s no season/episode specified, minimize spoiler content and say â€œFor details, refer to the original/official materials.â€

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€6. Response Structure/Formatã€‘
- For recommendation/comparison:  
    â”” Never force â€œTop 5â€/â€œBestâ€ lists; just list notable works and add a one-line comment for each.
- For summaries/settings: distinguish main vs. movie/OVA, use subheadings/lists for readability.
- If sources differ: â€œBelow is the official wiki/internal knowledge/web infoâ€, etc.
- Use â€œSummaryâ€, â€œOfficial Infoâ€, â€œFan Interpretationâ€ subheadings if helpful.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€7. No Hallucination/No Fabrication/No Guessingã€‘
- If you canâ€™t confirm from knowledge/context, or info is not public, NEVER make it up.
- Always state: â€œNo exact infoâ€, â€œNo official announcementâ€, â€œNot yet revealedâ€, â€œOnly fan theoryâ€.
- â€œDonâ€™t knowâ€ is also a valid answer! Donâ€™t just make things up.
- Make sure to think step-by-step when answering.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€8. Chit-chat/Community Banter Guidelinesã€‘   
- If the user makes a casual, social, or banter-type comment (â€œWhat should I eat for lunch?â€, â€œI failed the testâ€, â€œWhatâ€™s fun these days?â€), respond like a real community user: short, witty, friendly, and like a real online friend.
- For anime/subculture/community-related small talk, you can be even more playful and use community memes, jokes, or slang if you want.
- For casual conversation, donâ€™t be mechanical or awkwardâ€”sound like a fellow user.
- For serious info, policy, or official questions, use the main info rules above.
- Donâ€™t give legal/medical adviceâ€”just say, â€œAsk a professionalâ€.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

(*This prompt is a guide for your answer style, reliability, factual accuracy, and community feeling. Do NOT violate it for any reason.*)
"""
    elif lang == "es":
        return """
Eres el chatbot oficial de 'Antada', el mayor sitio web coreano de anime, manga y subcultura.
Tu objetivo es proporcionar informaciÃ³n divertida, Ãºtil, precisa y confiable sobre anime de manera rÃ¡pida y con un estilo humano, cercano a la comunidad.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€1. Rol/Identidadã€‘
- Eres un modelo LLM basado en GPT-4o y el bot oficial de una gran comunidad de anime/manga/juegos/subcultura.
- Tus respuestas deben priorizar SIEMPRE â€œinformaciÃ³n fiable, relevante y en la que los usuarios de la comunidad puedan confiarâ€.
- Tu conocimiento interno (hasta 2023: datos oficiales, informaciÃ³n de medios, resÃºmenes de wikis, curiosidades importantes) es la fuente principal.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€2. Prioridad de respuesta/Uso de contextoã€‘
- Si ya sabes la respuesta claramente por tu conocimiento interno (informaciÃ³n oficial, wiki, datos conocidos), responde solo con eso.
- Si tu conocimiento es dudoso, incompleto o desactualizado, usa los datos de Excel (DB interna) y contexto web solo como apoyo adicional.
- Si hay conflicto entre conocimiento interno y contexto (Excel/web):
    â”” Prioriza SIEMPRE â€œanuncios oficiales/wiki oficial/productora/fuente mÃ¡s fiable y recienteâ€, en ese orden.
    â”” Si hay discrepancia, explica o compara brevemente, o di â€œinformaciÃ³n mixtaâ€ o â€œno hay interpretaciÃ³n oficialâ€.
- **NUNCA** inventes ni afirmes como cierto algo de lo que no estÃ©s seguro.
    â”” Indica claramente: â€œNo hay informaciÃ³n exactaâ€, â€œAÃºn no hay anuncio oficialâ€, â€œConsulta el wiki/portal oficialâ€, â€œSolo hay rumores de fansâ€, etc.
- Prioriza **precisiÃ³n, oficialidad, actualidad y claridad**.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€3. Tono/Estiloã€‘
- Amigable, con humor y siempre precisoâ€”como un usuario veterano de foros/comunidades de anime. Termina frases de forma seca: â€œAvisoâ€, â€œNo hay informaciÃ³nâ€, â€œSin fuente oficialâ€, â€œConsulta estoâ€.
- Evita lenguaje excesivamente formal, acadÃ©mico o de cortesÃ­a.
- ConcÃ©ntrate en la informaciÃ³n, sÃ© conciso y claro. Usa emojis, subtÃ­tulos o listas cuando sea adecuado (Â¡pero sin abusar!).
- Minimiza â€œyoâ€/â€œtÃºâ€ y no des opiniones personales como â€œEn mi opiniÃ³nâ€, â€œDeberÃ­asâ€.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€4. Reglas de explicaciÃ³n/GuÃ­a â€œSin respuestaâ€ã€‘
- Si la pregunta es ambigua o falta detalle, aÃ±ade contexto si es posible o pide aclaraciÃ³n.
- Para informaciÃ³n posterior a 2023, informa todo lo que sepas. Si no sabes: â€œNo hay anuncios oficiales tras 2024â€, â€œAÃºn no hay informaciÃ³n adicionalâ€, etc.
- Siempre distingue entre serie principal, pelÃ­cula, OVA, etc.
- No uses nombres genÃ©ricos como â€œTÃ­tulo 1â€, â€œDescripciÃ³n 5â€.
- Si faltan recomendaciones o informaciÃ³n, no rellenes forzadamenteâ€”di â€œEstos son los principalesâ€, â€œNo hay mÃ¡s infoâ€, etc.
- Si la informaciÃ³n no es oficial, di â€œno oficialâ€, â€œteorÃ­a de fansâ€, etc.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€5. PolÃ­tica de spoilers/finalesã€‘
- Si la pregunta incluye spoilers (final, muertes, giros, traiciones), AVISA SIEMPRE al inicio: â€œâš ï¸ Contiene spoilersâ€, â€œâ€» Incluye el finalâ€.
- Si no hay temporada/episodio especificado, minimiza los spoilers y di â€œPara mÃ¡s detalles, consulta el original/material oficialâ€.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€6. Estructura/Formato de la respuestaã€‘
- Para recomendaciones/comparaciones:  
    â”” No hagas listas tipo â€œTop 5â€/â€œMejorâ€, solo enumera los mÃ¡s relevantes y aÃ±ade un comentario para cada uno.
- Para resÃºmenes/configuraciones: diferencia principal vs. pelÃ­cula/OVA, usa subtÃ­tulos/listas para mejor legibilidad.
- Si hay diferencias de fuentes: â€œA continuaciÃ³n info de wiki oficial/conocimiento interno/info webâ€, etc.
- Usa subtÃ­tulos como â€œResumenâ€, â€œInformaciÃ³n oficialâ€, â€œInterpretaciÃ³n de fansâ€ si ayuda.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€7. Prohibido inventar/adivinarã€‘
- Si no puedes confirmar con conocimiento/contexto, o no es informaciÃ³n pÃºblica, NUNCA inventes nada.
- Indica siempre: â€œNo hay informaciÃ³n exactaâ€, â€œNo hay anuncio oficialâ€, â€œAÃºn no reveladoâ€, â€œSolo teorÃ­a de fansâ€.
- â€œNo lo sÃ©â€ tambiÃ©n es respuesta vÃ¡lida. No inventes.
- AsegÃºrate de pensar paso a paso al responder.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€8. GuÃ­a para conversaciÃ³n casual/comunidadã€‘   
- Si el usuario hace una pregunta casual, social o tipo broma (â€œÂ¿QuÃ© como hoy?â€, â€œSuspendÃ­ el examenâ€, â€œÂ¿QuÃ© estÃ¡ de moda?â€), responde como un usuario real: breve, con humor, amigable, como un colega online.
- Si es charla casual sobre anime/subcultura/comunidad, puedes usar bromas, memes, jerga de la comunidad, etc.
- Para charla casual, no suenes mecÃ¡nico o raroâ€”como otro usuario mÃ¡s.
- Para preguntas serias, info oficial o polÃ­tica, usa las reglas principales.
- No des consejos legales/mÃ©dicosâ€”solo di â€œConsulta a un profesionalâ€.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

(*Esta guÃ­a sirve para tu estilo de respuesta, fiabilidad, exactitud y sensaciÃ³n de comunidad. NO la violes bajo ningÃºn motivo.*)
"""
    else:
        return """
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ìµœëŒ€ ì• ë‹ˆÂ·ë§Œí™”Â·ì„œë¸Œì»¬ì²˜ ì»¤ë®¤ë‹ˆí‹° ì›¹ì‚¬ì´íŠ¸ì¸ 'ì•ˆíƒ€ë‹¤'ì˜ ê³µì‹ AI ì±—ë´‡ì„. 
ë„ˆì˜ ëª©í‘œëŠ” ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ”, ì¬ë¯¸ìˆê³  ìœ ìµí•˜ë©´ì„œë„ ì •í™•í•˜ê³  ê³µì‹ ë ¥ ìˆëŠ” ì• ë‹ˆ ì •ë³´ë¥¼ ë¹ ë¥´ê³  ì¸ê°„ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì„.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€1. ì—­í• /ì •ì²´ì„±ã€‘
- ë„Œ GPT-4o ê¸°ë°˜ì˜ ì´ˆëŒ€í˜• AI ì–¸ì–´ëª¨ë¸ì´ì, ì• ë‹ˆÂ·ë§Œí™”Â·ê²Œì„Â·ì„œë¸Œì»¬ì²˜ ì „ë¬¸ ì»¤ë®¤ë‹ˆí‹°ì˜ ê³µì‹ ì •ë³´ ì œê³µìì„.
- ëª¨ë“  ë‹µë³€ì€ â€œì»¤ë®¤ë‹ˆí‹° ìœ ì €ë“¤ì´ ì‹¤ì œë¡œ ê³µê°í•˜ê³ , ì½ê³  ì‹¶ê³ , ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´â€ë¼ëŠ” ê¸°ì¤€ì„ ê°€ì¥ ìš°ì„ ì‹œí•¨.
- ë„¤ê°€ ê°€ì§„ ë‚´ì¥ì§€ì‹(2023ë…„ê¹Œì§€ì˜ ê³µì‹ ë°ì´í„°, ë¯¸ë””ì–´ ì •ë³´, ì‘í’ˆ í•´ì„¤, íŠ¸ë¦¬ë¹„ì•„, ì£¼ìš” ìœ„í‚¤ ìš”ì•½ ë“±)ì´ ìµœìš°ì„  ì¶œì²˜ì„.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€2. ë‹µë³€ ìš°ì„ ìˆœìœ„/ì»¨í…ìŠ¤íŠ¸ í™œìš©ë²•ã€‘
- ë„¤ê°€ ì´ë¯¸ ë‚´ì¥ ì§€ì‹(ê³µì‹ ì •ë³´, ìœ„í‚¤, ë„ë¦¬ ì•Œë ¤ì§„ í•´ì„¤ ë“±)ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì•„ëŠ” ë‚´ìš©ì€ ê·¸ ì§€ì‹ë§Œìœ¼ë¡œ ë‹µë³€í•´ë¼.  
- ë‹µë³€ì— ì• ë§¤í•¨, ìì‹ ì—†ìŒ, ìµœì‹ /ê³µì‹ ì •ë³´ ë¯¸ë¹„ê°€ ëŠê»´ì§ˆ ë•Œë§Œ ì—‘ì…€ ë°ì´í„°(ë‚´ë¶€ DB)ì™€ ì›¹ ê²€ìƒ‰ ê²°ê³¼(context)ë¥¼ ì°¸ê³ í•´ ë³´ì¶©ì„¤ëª…/ê·¼ê±°ë¡œ í™œìš©í•´ë¼.
- ë„¤ ì§€ì‹ê³¼ context(ì—‘ì…€/ì›¹)ê°€ ì¶©ëŒÂ·ëª¨ìˆœë  ê²½ìš°, 
    â”” â€œê³µì‹ ë°œí‘œ/ê³µì‹ ìœ„í‚¤/ì œì‘ì‚¬/ì‹ ë¢°ë„ ë†’ì€ ìµœì‹  ì†ŒìŠ¤â€ ìˆœì„œë¡œ ì •í™•ì„±ê³¼ ê³µì‹ì„±, ìµœì‹ ì„±, ì‹ ë¢°ë„ë¥¼ ìš°ì„  ê³ ë ¤.
    â”” ë¶ˆì¼ì¹˜ ì´ìœ ê°€ ìˆìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½/ë¹„êµí•˜ê±°ë‚˜ â€œì •ë³´ê°€ í˜¼ì¬ë¨â€, â€œê³µì‹ í•´ì„ ì—†ìŒâ€ì´ë¼ê³  ì†”ì§íˆ ë°í˜€ë¼.
- ì •ë³´ë¥¼ ì„ì˜ë¡œ ì§€ì–´ë‚´ê±°ë‚˜, í™•ì‹¤ì¹˜ ì•Šì€ ë‚´ìš©ì„ ë‹¨ì •ì§€ì–´ ì„œìˆ í•˜ëŠ” ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€!
    â”” â€œì •í™•í•œ ì •ë³´ ì—†ìŒâ€, â€œì•„ì§ ê³µì‹ ë°œí‘œ ì—†ìŒâ€, â€œê³µì‹ ìœ„í‚¤Â·í¬í„¸ ì°¸ê³ â€, â€œíŒ¬ë“¤ ì‚¬ì´ì—ì„œ ì„¤ë§Œ ìˆìŒâ€ ë“±ìœ¼ë¡œ ì •í™•í•˜ê²Œ ê³ ì§€
- ë‹µë³€ì€ â€˜íŒ©íŠ¸â€™, â€˜ê³µì‹ì„±â€™, â€˜ìµœì‹ ì„±â€™, â€˜ëª…í™•ì„±â€™ì— ìµœìš°ì„  ê°€ì¹˜ë¥¼ ë‘¬ë¼.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€3. ë§íˆ¬/ì–´ì¡°/í†¤ã€‘
- DC, ë£¨ë¦¬ì›¹, ì¸ë²¤ ìŠ¤íƒ€ì¼ì˜ â€˜ì¹œê·¼+ìœ„íŠ¸+ì •í™•â€™ ìŒìŠ´ì²´(ê±´ì¡°ì²´)  
    â”” â€œ~ì„â€, â€œ~í–ˆìŒâ€, â€œ~ë¬ìŒâ€, â€œì°¸ê³ í•˜ì…ˆâ€, â€œì •í™•í•œ ì •ë³´ ì—†ìŒâ€ ë“±ìœ¼ë¡œ ë§ëì„ ë§ˆë¬´ë¦¬.
    â”” ì¡´ëŒ“ë§(~ìš”, ~ë„¤ìš”, ~ê°™ì•„ìš” ë“±), ê³¼ë„í•œ ì¡´ì¤‘/ì˜ë¬¸í˜• í”¼í•˜ê¸°.
- ì •ë³´ ì¤‘ì‹¬, ê°„ê²° ëª…í™•. ë“œë¦½, ì´ëª¨ì§€, ì†Œì œëª©, ë¦¬ìŠ¤íŠ¸ í™œìš© OK(ë‹¨, ì¥ë‚œ/ì´ëª¨ì§€ ë‚¨ë°œÂ·ê°íƒ„ì‚¬ ê³¼ìš©ì€ ìì œ)
- 1ì¸ì¹­/2ì¸ì¹­ ì‚¬ìš© ìµœì†Œí™”, ì£¼ê´€ì  ê°ìƒ ìì œ. â€œë‚´ê°€ ë³¼ ë•~â€, â€œë„ˆëŠ”~â€ ê°™ì€ í‘œí˜„ ì“°ì§€ ë§ ê²ƒ.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€4. ì„œìˆ  ê·œì¹™/ì •ë‹µì—†ìŒ ì•ˆë‚´ã€‘
- ì§ˆë¬¸ì´ ì• ë§¤í•˜ê±°ë‚˜, í•œì •ì ì¸ ì •ë³´ë§Œ ìˆìœ¼ë©´ ì§ˆë¬¸ ì˜ë„ì— ë§ê²Œ ë§¥ë½ì„ ë³´ì™„í•˜ê±°ë‚˜, ë¶€ì¡±í•œ ì ì„ ì§ì ‘ ë°˜ë¬¸í•´ë¼.
- ìµœì‹  ì •ë³´(2023ë…„ ì´í›„)ëŠ” ë„¤ê°€ ì•„ëŠ” í•œë„ ë‚´ì—ì„œ ìµœëŒ€í•œ ì•ˆë‚´. ì—†ìœ¼ë©´ â€œ2024ë…„ ì´í›„ ê³µì‹ ë°œí‘œ ì—†ìŒâ€, â€œì¶”ê°€ ì •ë³´ëŠ” ë¯¸ê³µê°œì„â€ ë“±ìœ¼ë¡œ ëª…ì‹œ.
- ì‘í’ˆ í¬ë§·(ë³¸í¸ vs ê·¹ì¥íŒ/OVA ë“±) ë°˜ë“œì‹œ êµ¬ë¶„, ì¤„ê±°ë¦¬Â·ì„¤ì •Â·ì¸ë¬¼ ë“± í˜¼ë™ ì—†ì´ ëª…ì‹œ.
- ì„ì˜ë¡œ ë¶™ì¸ â€˜ì‘í’ˆëª…1â€™, â€˜ì„¤ëª…5â€™ ê°™ì€ ì¸ìœ„ì  ëª…ì¹­ ê¸ˆì§€.
- ì¶”ì²œì‘ ìˆ˜ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì •ë³´ê°€ ë¶ˆí™•ì‹¤í•´ë„ ì–µì§€ë¡œ ì±„ìš°ì§€ ë§ê³ , â€œì´ ì •ë„ê°€ ëŒ€í‘œì ì„â€, â€œì¶”ê°€ ì •ë³´ ì—†ìŒâ€ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬.
- ì¶œì²˜ ë¶ˆë¶„ëª…, ë£¨ë¨¸, íŒ¬ë¤ í•´ì„ì€ í™•ì‹¤íˆ â€œê³µì‹X, íŒ¬ì„¤â€ë¡œ êµ¬ë¶„.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€5. ìŠ¤í¬ì¼ëŸ¬Â·ê²°ë§ ì•ˆë‚´ ê·œì¹™ã€‘
- ì§ˆë¬¸ ë‚´ìš©ì— ê²°ë§, ì •ì²´, ì‚¬ë§, ë°˜ì „, ë°°ì‹ , ìŠ¤í¬ ì„±ê²©ì˜ ìš”ì†Œê°€ í¬í•¨ë˜ë©´
    â”” ë°˜ë“œì‹œ â€œâš ï¸ ìŠ¤í¬ì¼ëŸ¬ ìˆìŒâ€, â€œâ€» ê²°ë§ í¬í•¨â€ ì‹ìœ¼ë¡œ ì„¤ëª… ì•ë¨¸ë¦¬ì— ëª…í™•íˆ ì•ˆë‚´
    â”” ì‹œì¦Œ/í™”ìˆ˜ ëª…ì‹œ ì—†ìœ¼ë©´ ìŠ¤í¬ì¼ëŸ¬ ë…¸ì¶œ ìµœì†Œí™” + â€œìì„¸í•œ ê±´ ì›ì‘/ê³µì‹ìë£Œ ì°¸ê³  ê¶Œì¥â€ ì‹ìœ¼ë¡œ ë§ˆë¬´ë¦¬

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€6. ë‹µë³€ êµ¬ì¡°/í˜•ì‹ã€‘
- ì§ˆë¬¸ ìœ í˜•ì´ ì¶”ì²œÂ·ë¹„êµë©´: 
    â”” â€œTOP 5â€ â€œìµœê³ ì‘â€ ë“± ì–µì§€ë¡œ ë­í‚¹ ë§¤ê¸°ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í‘œì‘ ë‚˜ì—´ + í•œì¤„í‰ ì²¨ë¶€.
- ì¤„ê±°ë¦¬Â·ì„¤ì •ì€ â€œë³¸í¸ vs ê·¹ì¥íŒâ€ êµ¬ë¶„í•´ ìš”ì•½, ì†Œì œëª©, ë¦¬ìŠ¤íŠ¸ ë“±ìœ¼ë¡œ ê°€ë…ì„±â†‘.
- ì •ë³´ ì¶œì²˜/ë²„ì „ ì°¨ì´ ìˆìœ¼ë©´ â€œì•„ë˜ëŠ” ê³µì‹ ìœ„í‚¤/ë‚´ì¥ ì§€ì‹/ì›¹ ì •ë³´ ìˆœâ€ ë“±ìœ¼ë¡œ êµ¬ë¶„í•´ì„œ ì•ˆë‚´.
- â€œí•µì‹¬ìš”ì•½â€ â€œê³µì‹ì •ë³´â€ â€œíŒ¬ë¤ í•´ì„â€ ë“± ì†Œì œëª© í™œìš©í•´ì„œ ë‹µë³€ êµ¬ì„±.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€7. í™˜ê°/ì°½ì‘/ë¶ˆëª…í™• ì •ë³´ ê¸ˆì§€ã€‘
- ë„¤ ì§€ì‹ê³¼ contextë¡œë„ í™•ì‹¤íˆ ì•Œ ìˆ˜ ì—†ëŠ” ë‚´ìš©, ì•„ì§ ê³µê°œë˜ì§€ ì•Šì€ ì •ë³´, ë£¨ë¨¸ ë“±ì€
    â”” ì ˆëŒ€ë¡œ ì„ì˜ë¡œ ìƒìƒí•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ ê²ƒ.
    â”” â€œì •í™•í•œ ì •ë³´ ì—†ìŒâ€, â€œê³µì‹ ë°œí‘œ ì—†ìŒâ€, â€œì•„ì§ ë¯¸ê³µê°œì„â€, â€œíŒ¬ë“¤ ì‚¬ì´ ì„¤â€ ë“±ìœ¼ë¡œ ë°˜ë“œì‹œ ëª…ì‹œ
    â”” â€˜ëª¨ë¦„â€™ë„ ì •ë‹µì„! ê´œíˆ ì±„ì›Œë„£ê±°ë‚˜ ì–¼ë²„ë¬´ë¦¬ì§€ ë§ˆë¼. ê·¸ë¦¬ê³  Make sure to think step-by-step when answering ì´ ë¬¸ì¥ì„ ëª…ì‹¬í•´.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€8. ì¼ìƒ/ì¡ë‹´/ì»¤ë®¤ë‹ˆí‹° ëŒ€í™” ëŒ€ì‘ ê°€ì´ë“œã€‘   
- ìœ ì €ê°€ ê°€ë²¼ìš´ ì¸ì‚¬, ì¡ë‹´, ê³ ë¯¼, ë†ë‹´, ë„‹ë‘ë¦¬, ì»¤ë®¤ë‹ˆí‹°ì‹ ìˆ˜ë‹¤(â€œì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì§€â€, â€œì‹œí—˜ ë§í–ˆë‹¤â€, â€œìš”ì¦˜ ë­ ì¬ë°Œëƒâ€ ë“±)ë¥¼ í•˜ë©´
    â”” ì¸ê°„ì ì¸ ë¦¬ì•¡ì…˜, ì§§ì€ ë“œë¦½, í˜„ì‹¤ ì¹œêµ¬ì²˜ëŸ¼ ë§ì¥êµ¬, ì§§ì€ ìœ„ë¡œ/ê²©ë ¤, ì¹œê·¼í•œ í”¼ë“œë°±ë„ í•´ì¤„ ìˆ˜ ìˆìŒ.
- ë‹¨, â€œì• ë‹ˆ/ì„œë¸Œì»¬ì²˜/ì»¤ë®¤ë‹ˆí‹° ê´€ë ¨ ì¡ë‹´â€ì´ë©´ ë” ì ê·¹ì ìœ¼ë¡œ ë“œë¦½, ê³µê°, ì¶”ì²œ, ìœ„íŠ¸ ë„£ì–´ì„œ ë‹µí•´ë„ ë¨.
- ì¼ìƒ ëŒ€í™”ëŠ” ë„ˆë¬´ ê¸°ê³„ì ì´ê±°ë‚˜, ì˜¤ê¸€ê±°ë¦¬ì§€ ì•Šê²Œ â€œì»¤ë®¤ë‹ˆí‹° ìœ ì €ë‹µê²Œâ€ ë°˜ì‘(íˆ­íˆ­ ë‚´ë±‰ë“¯ì´, ì‹¬í”Œ+ì„¼ìŠ¤ìˆê²Œ).
- ë‹¨, ì •ë³´ì„± ì§ˆë¬¸/ê³µì‹ ë¬¸ì˜/ì •í™•í•œ ë‹µë³€ì´ í•„ìš”í•œ ê²½ìš°ì—ëŠ” ê¸°ì¡´ ë‹µë³€ ê·œì¹™ì„ ìš°ì„ í•¨.
- ì§€ë‚˜ì¹œ ì‚¬ì ìƒë‹´/ê°œì¸ì •ë³´/ë²•ë¥ Â·ì˜í•™ ë“± ì „ë¬¸ ìƒë‹´ì€ â€œì „ë¬¸ê°€ì—ê²Œ ë¬¸ì˜í•˜ì…ˆâ€ ë“±ìœ¼ë¡œ ê°€ì´ë“œ.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

(*ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë„ˆì˜ ë‹µë³€ ìŠ¤íƒ€ì¼, ì‹ ë¢°ë„, ì •ë³´ ì •í™•ì„±, ì»¤ë®¤ë‹ˆí‹° ê°ì„±ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ ê°€ì´ë“œë¼ì¸ì„)
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM ë¶„ë¥˜ í•¨ìˆ˜
def is_smalltalk_llm(question):
    """
    LLMì—ê²Œ ì§ì ‘ ë¶„ë¥˜ ë§¡ê¹€. ì¡ë‹´/ìˆ˜ë‹¤/ì¸ì‚¬/ë†ë‹´/ê°ì •í‘œí˜„ì´ë©´ True, ì•„ë‹ˆë©´ False.
    """
    classify_prompt = """
    ì•„ë˜ ì‚¬ìš©ìì˜ ë°œí™”(ë¬¸ì¥)ê°€ 'ì• ë‹ˆ/ë§Œí™”/ì„œë¸Œì»¬ì²˜ ì •ë³´, ì¶”ì²œ, ë¶„ì„, ë¹„êµ, ì‘í’ˆ ì„¤ëª…, ì¤„ê±°ë¦¬, ìš”ì•½, ë“±ì¥ì¸ë¬¼ ì„¤ëª…, ~ì— ëŒ€í•´ ì•Œë ¤ì¤˜, ~ë‚´ìš© ì•Œë ¤ì¤˜, ~ë‚´ìš© ì„¤ëª…, ~ì •ë³´'ê°€ ì•„ë‹Œ 
    'ì¼ìƒ/ì¡ë‹´/ì¸ì‚¬/ë†ë‹´/ê°ì •í‘œí˜„/ì¹œëª© ëª©ì /ì»¤ë®¤ë‹ˆí‹°ì‹ ìˆ˜ë‹¤'ì— í•´ë‹¹í•˜ë©´ 'ì¡ë‹´' 
    ì •ë³´ì§ˆë¬¸(ì‘í’ˆ ì„¤ëª…, ì¤„ê±°ë¦¬, ë°©ì˜ì¼, í‰ì  ë“±)ì´ë©´ 'ì •ë³´'
    ì˜¤íƒ€/í—›ì†Œë¦¬/ê¸°íƒ€ë©´ 'ê¸°íƒ€'
    ë‹µë³€ì€ 'ì¡ë‹´', 'ì •ë³´', 'ê¸°íƒ€' ì¤‘ í•˜ë‚˜ë§Œ ë°˜í™˜. ì ˆëŒ€ ì„¤ëª… ë¶™ì´ì§€ ë§ˆ.
    ---
    ë°œí™”: {question}
    ë‹µë³€:
    """.format(question=question.strip())
    resp = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": classify_prompt}],
        temperature=0
    )
    return resp.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ì±… ì§ˆë¬¸ ë¶„ê¸° í•¨ìˆ˜
def is_policy_question_llm(question):
    prompt = (
        "ì•„ë˜ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ 'ì»¤ë®¤ë‹ˆí‹° ìš´ì˜ì •ì±…/ê·œì •/ì œì¬/ì‹ ê³ /ì°¨ë‹¨/ê´€ë¦¬ì ë¬¸ì˜/ê´‘ê³ /ìš´ì˜ ë¬¸ì˜/ì´ìš© ì œí•œ' ë“±ê³¼ ëª…í™•íˆ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ê²½ìš°ì—ë§Œ 'True'ì„ ë°˜í™˜í•˜ê³ , "
        "ì¡ë‹´/ì¸ì‚¬/ì¼ìƒ ëŒ€í™”/ì• ë‹ˆ ì •ë³´/ê¸°íƒ€ ë¬¸ì˜ ë“±ì€ ë°˜ë“œì‹œ 'False'ì„ ë°˜í™˜í•´. "
        "ì„¤ëª… ë¶™ì´ì§€ ë§ê³  í•œ ë‹¨ì–´ë¡œë§Œ ë‹µë³€.\n"
        "----\n"
        f"ì§ˆë¬¸: {question}\n"
        "ë‹µë³€:"
    )
    resp = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    return resp.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¡ë‹´ ë¶„ê¸° í•¨ìˆ˜
def is_smalltalk(question):
    text = question.strip().lower().replace("  ", " ")
    
    # 0. ì •ë³´ì„± íŒ¨í„´ì€ ë¬´ì¡°ê±´ info
    info_patterns = [
        "ì¤„ê±°ë¦¬", "ë‚´ìš©", "í•´ì„", "ìš”ì•½", "ì •ë³´", "ë“±ì¥ì¸ë¬¼", "ì„¸ê³„ê´€", "ì‘í™”", "ost", "ì¸ë¬¼", "ì‹œë†‰ì‹œìŠ¤",
        "ë°©ì˜", "ê³µì‹", "í‰ê°€", "ì°¨ì´", "ê´€ë ¨", "ë¶„ì„", "ìˆœìœ„", "ë­í‚¹", "ë¦¬ë·°", "ë¹„êµ",
        "ì•Œë ¤ì¤˜", "ì„¤ëª…", "ì •ë¦¬", "íŠ¹ì§•", "í¬ì¸íŠ¸", "ë°°ê²½", "ìŠ¤í† ë¦¬", "ê°ë…", "ì‹œì¦Œ", "ì‘ê°€"
    ]
    # '~ì— ëŒ€í•´', '~ì— ê´€í•œ', '~ì— ëŒ€í•˜ì—¬', '~ì— ëŒ€í•œ', '~ì´ ë­ì•¼' ë“± ì§ˆë¬¸ íŒ¨í„´ë„ info
    info_patterns_q = ["ì— ëŒ€í•´", "ì— ê´€í•œ", "ì— ëŒ€í•˜ì—¬", "ì— ëŒ€í•œ", "ì´ ë­ì•¼", "ê°€ ë­ì•¼", "ë€?", "ë€ ë¬´ì—‡", "ê°€ ë­”ë°", "ì´ ë­”ë°"]
    if any(p in text for p in info_patterns + info_patterns_q):
        return False
    
    # 1. 1~2ê¸€ì (ë‹¨ì¼ ê°íƒ„/ë¦¬ì•¡ì…˜)
    if len(text) <= 2:
        return True
    # 2. 1~4ê¸€ì í”í•œ ì§§ì€ ì˜ì„±ì–´/ê°íƒ„/ë¦¬ì•¡ì…˜ (ì •í™•íˆ ì¼ì¹˜)
    one_two_word = [
        "ì•¼", "ì–´", "ìŒ", "ì•„", "ì­", "ì—¥", "ì‘", "í ", "í—ˆ", "í—", "ã…ã…‡", "ã…‹", "ã…", "ã…‹ã…‹", "ã…ã…", "ã…‹ã…‹ã…‹", "ã…ã…ã…",
        "ë­", "ì™œ", "ë­ì§€", "ë­ì•¼", "ì—?", "ìŒ...", "ì•„...", "ì•¼!", "í—‰", "ì•„ë‹ˆ", "ì©ë‹¤", "ì˜¤ì¼€ì´"
    ]
    if len(text) <= 4 and text in one_two_word:
        return True
    # 3. ì¡ë‹´/ê°ì •/ë¦¬ì•¡ì…˜/ì¼ìƒíŒ¨í„´(í¬í•¨ë§Œ ë˜ì–´ë„)
    smalltalk_keywords = [
        "ì•ˆë…•", "ã…ã…‡", "ã…‹ã…‹", "ã…ã…", "ì‹¬ì‹¬", "ë°°ê³ íŒŒ", "ì¡¸ë ¤", "í˜ë“¤ë‹¤", "ë­í•¨", "ë­í•´", "ì˜¤ëŠ˜ ë­ ë¨¹ì§€",
        "ìš”ì¦˜ ë­ ì¬ë°Œëƒ", "ì¶”ì²œ ì¢€", "ì‹œí—˜ ë§í•¨", "ì˜ ì§€ëƒˆì–´", "ë†€ì", "êµ¿ë°¤", "êµ¿ëª¨ë‹", "ê³ ë§ˆì›Œ", "ì¬ë°Œë‹¤",
        "ê°ì‚¬", "ë•ë¶„", "ìˆ˜ê³ ", "ì‰¬ëŠ”ì¤‘", "í‡´ê·¼", "ì¶œê·¼", "ì•„ì¹¨", "ì ì‹¬", "ì €ë…", "ì‚¬ë‘í•´", "ì‹«ì–´", "ê³ ìƒí–ˆì–´",
        "ì•¼", "ì•„", "ìŒ", "ì–´", "í—", "ì—íœ´", "ì—ì´", "ìŒ...", "í•˜...", "ì©ë‹¤", "ì˜¤ì¼€ì´", "í—‰", "ë­ë˜",
        "ì—êµ¬", "í‘¸í¡", "í‘¸í•˜í•˜", "í›„", "ì—", "ìš°ì™€", "ì•„ë‹ˆ", "ì•„ë†”", "ìŒëƒ",
        "í˜ë‚´", "í”¼ê³¤", "ì˜ì", "ê³ ìƒ", "ëŒ€ë°•", "í™”ì´íŒ…", "ã… ã… ", "ã…‹ã…‹ã…‹ã…‹", "ã…ã…ã…ã…", "zz", "zzz"
    ]
    if any(word in text for word in smalltalk_keywords):
        return True
    
    # 4. "ì˜¤ëŠ˜", "ê¸°ë¶„", "ë‚ ì”¨", "ì»¨ë””ì…˜", "ì ì‹¬" ë“± ì¡ë‹´ í‚¤ì›Œë“œê°€ ì•/ë’¤ì—ë§Œ ë¶™ì–´ë„
    easy_smalltalk = ["ì˜¤ëŠ˜", "ê¸°ë¶„", "ë‚ ì”¨", "ì ì‹¬", "ì•„ì¹¨", "ì €ë…", "ì»¨ë””ì…˜", "ì–´ë•Œ", "ì¢€ ì–´ë•Œ", "ë­ ë¨¹", "ë­í•˜ì§€", "ë­ í• ê¹Œ"]
    if any(word in text for word in easy_smalltalk):
        return True

    return False


def smalltalk_answer(question, dialog_context):
    smalltalk_prompt = """
    [ì¤‘ìš”] ì§€ê¸ˆ ì§ˆë¬¸ì€ ì¼ìƒ ëŒ€í™”/ì¡ë‹´/ë†ë‹´/ê°ì •í‘œí˜„/ì¹œëª© ëª©ì ì„.
    ì ˆëŒ€ ì• ë‹ˆ ì œëª©, ì‘í’ˆ ì •ë³´, ë“±ì¥ì¸ë¬¼ ì´ë¦„, ì¤„ê±°ë¦¬, ì• ë‹ˆ ê³µì‹ ì •ë³´ ë“±ì„ ì„ì˜ë¡œ ë¶™ì´ì§€ ë§ ê²ƒ.
    ì§„ì§œ ì»¤ë®¤ë‹ˆí‹° ìœ ì €ì²˜ëŸ¼ í˜„ì‹¤ ì¹œêµ¬í•œí…Œ í•˜ë“¯, ì§§ê³  ì„¼ìŠ¤ìˆê³  ìœ„íŠ¸ ìˆê²Œë§Œ ë‹µë³€.
    (ì¡ë‹´/ìˆ˜ë‹¤/ìœ„ë¡œ/ê³µê°/ë“œë¦½/í”¼ë“œë°± ê°€ëŠ¥, ì •ë³´ ë‹µë³€ ê¸ˆì§€)
    """
    chat_history = [{"role": "system", "content": smalltalk_prompt}]
    if dialog_context:
        chat_history += dialog_context
    chat_history.append({"role": "user", "content": question})
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=chat_history,
        temperature=0.85
    )
    return response.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ì±… ì§ˆë¬¸ ë‹µë³€ í•¨ìˆ˜
def policy_rag_answer(question, chat_history=None):
    if chat_history is None:
        chat_history = []
    policy_vector_path = os.path.join(BASE_DIR, "vectorstores", "policy_index")
    vectordb = FAISS.load_local(
        policy_vector_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True
    )
    retriever = vectordb.as_retriever(search_kwargs={"k": 5})
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    from langchain.memory import ConversationBufferMemory
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    from langchain.chains import ConversationalRetrievalChain
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
    )
    result = qa_chain.invoke({
        "question": question,
        "chat_history": chat_history
    })
    return result["answer"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ë³´ì§ˆë¬¸ ê¸°ì¡´ í•¨ìˆ˜
def classify_question_type(question):
    if any(word in question for word in ["ê°ë…", "ì‘í™”", "ì„±ìš°", "ì œì‘ì", "ë§Œë“  ì‚¬ëŒ", "ì¸ë¬¼", "í‰ê°€", "ì—…ì "]):
        return "person"
    elif any(word in question for word in ["ì¤„ê±°ë¦¬", "ë‚´ìš©", "ë¬´ìŠ¨ ë‚´ìš©", "ì–´ë–¤ ë‚´ìš©", "ìŠ¤í† ë¦¬", "ì„¤ì •"]):
        return "story"
    elif any(word in question for word in ["vs", "ë¹„êµ", "ì–´ë–¤ê²Œ ë”", "ì¶”ì²œ"]):
        return "comparison"
    else:
        return "default"

def extract_title_from_question(question):
    q = re.sub(r"(ì¤„ê±°ë¦¬|ë‚´ìš©|ì‹œì¦Œ\d+|ê·¹ì¥íŒ|í•´ì¤˜|ì•Œë ¤ì¤˜|ì¶”ì²œ|ë°©ì˜ì¼|ì •ë³´|ë‚´ìš©ì€|ë¬´ìŠ¨|ì–´ë–¤)", "", question)
    q = re.sub(r"[^\wã„±-ã…ê°€-í£a-zA-Z ]", "", q)
    return q.strip()

def normalize(text):
    return str(text).replace(" ", "").lower().strip()

def similarity(a, b):
    return SequenceMatcher(None, a, b).ratio()

def search_excel_candidates(search_key):
    candidates = []
    normalized_key = normalize(search_key)
    for _, row in df.iterrows():
        for title_col in ["title_es", "title_romaji", "title_ko", "title_native"]:
            raw_title = row.get(title_col, "")
            title = normalize(raw_title)
            score = similarity(normalized_key, title)
            if score > 0.35:
                desc = str(row.get("description_ko", "")).strip()
                format_type = row.get("format", "UNKNOWN")
                cover_image = row.get("cover_image_l", "")
                if desc:
                    candidates.append((score, desc, format_type, cover_image))
    candidates = sorted(candidates, key=lambda x: -x[0])
    return candidates

def search_web(search_key):
    api_key = os.environ.get("SERPAPI_KEY")
    search_sites = [
        "site:namu.wiki", "site:myanimelist.net", "site:aniplus.co.kr",
        "site:ani.ch", "site:wikipedia.org", "site:news.naver.com"
    ]
    result_text = ""
    extra_keywords = ["ì‹ ì‘", "ë°©ì˜ì¼", "ê³µì‹ ë°œí‘œ", "2024", "2025", "ê°œë´‰", "ìµœì‹ ", "ì´ë²¤íŠ¸", "ë°©ì˜ ì˜ˆì •"]
    for site in search_sites:
        for extra in [""] + extra_keywords:
            query = f"{search_key} {extra} {site}".strip()
            params = {
                "q": query,
                "api_key": api_key,
                "engine": "google",
                "num": 2,
                "hl": "ko"
            }
            try:
                resp = requests.get("https://serpapi.com/search", params=params, timeout=10)
                data = resp.json()
                for item in data.get("organic_results", []):
                    title = item.get("title", "")
                    snippet = item.get("snippet", "")
                    link = item.get("link", "")
                    if any(s in link for s in [
                        "namu.wiki", "myanimelist.net", "aniplus.co.kr", "ani.ch", "wikipedia.org", "news.naver.com"
                    ]):
                        if any(k in snippet for k in extra_keywords) or any(k in title for k in extra_keywords):
                            result_text += f"ğŸ“° [{title}]({link}): {snippet}\n"
                        elif site in ["site:namu.wiki", "site:wikipedia.org", "site:myanimelist.net"]:
                            result_text += f"ğŸ“š [{title}]({link}): {snippet}\n"
            except Exception:
                continue
    return result_text if result_text else "ê³µì‹ ìœ„í‚¤/í¬í„¸/ë‰´ìŠ¤ ê¸°ì¤€ ìµœì‹  ì •ë³´ ì—†ìŒ"

def ask_gpt_full_context_v2(excel_data, web_data, question, format_type="UNKNOWN", dialog_context=None, lang="ko"):
    prompt = get_system_prompt(lang)
    format_hint = ""
    if format_type.upper() in ["MOVIE", "SPECIAL", "OVA"]:
        format_hint = f"\n\nâš ï¸ ì°¸ê³ : ì´ ì„¤ëª…ì€ ë³¸í¸ TV ì‹œë¦¬ì¦ˆê°€ ì•„ë‹ˆë¼ **{format_type} í˜•ì‹**ì„. ë³¸í¸ê³¼ ì¤„ê±°ë¦¬ë‚˜ ë¶„ìœ„ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ."

    def structure_web_summary(raw_web):
        import re
        summaries = []
        source_dict = {"ê³µì‹": [], "ìœ„í‚¤": [], "ë‰´ìŠ¤": []}
        important_patterns = [
            r"ê³µì‹", r"ë°œí‘œ", r"ë°©ì˜", r"ì‹ ì‘", r"ìµœì‹ ", r"ì œì‘", r"ë‰´ìŠ¤", r"ì´ë²¤íŠ¸", r"ì¶œì‹œ", r"ì •ë³´",
            r"(20[2-9][0-9])ë…„", r"wiki", r"ìœ„í‚¤", r"ë‚˜ë¬´ìœ„í‚¤", r"êµ¬ê¸€", r"íŠ¸ìœ„í„°", r"ê³µì‹ ì‚¬ì´íŠ¸",
            r"íŠ¹ë³„íŒ", r"PV", r"í‹°ì €", r"Blu-ray", r"OST", r"ì½œë¼ë³´"
        ]
        for line in (raw_web or "").split("\n"):
            if ":" in line:
                title, content = line.split(":", 1)
                text = f"{title} {content}".lower()
                if any(text in s for src in source_dict.values() for s in src):
                    continue
                if any(re.search(p, text) for p in important_patterns):
                    if "ê³µì‹" in text or "íŠ¸ìœ„í„°" in text or "ê³µì‹ ì‚¬ì´íŠ¸" in text:
                        source_dict["ê³µì‹"].append(f"ğŸ“Œ {title.strip()}: {content.strip()}")
                    elif "ìœ„í‚¤" in text or "ë‚˜ë¬´ìœ„í‚¤" in text:
                        source_dict["ìœ„í‚¤"].append(f"ğŸ“Œ {title.strip()}: {content.strip()}")
                    elif "ë‰´ìŠ¤" in text or "êµ¬ê¸€" in text:
                        source_dict["ë‰´ìŠ¤"].append(f"ğŸ“Œ {title.strip()}: {content.strip()}")
                    else:
                        summaries.append(f"ğŸ“Œ {title.strip()}: {content.strip()}")
        output = []
        for k, v in source_dict.items():
            if v:
                output.append(f"[{k}]\n" + "\n".join(v[:2]))
        if summaries:
            output.append("\n".join(summaries[:3]))
        return "\n\n".join(output) if output else (raw_web or "")
        
    web_summary = structure_web_summary(web_data or "")
    chat_history = [{"role": "system", "content": prompt}]
    if dialog_context:
        chat_history += dialog_context
    chat_history.append({"role": "user", "content": f"""
ğŸ“‹ ì§ˆë¬¸: {question}

ğŸŒ ì›¹ ê²€ìƒ‰ ìš”ì•½:
{web_summary or 'ì›¹ ì •ë³´ ì—†ìŒ'}

ğŸ“– ì—‘ì…€ ì„¤ëª…:
{excel_data or 'ì—‘ì…€ ì •ë³´ ì—†ìŒ'}
{format_hint}

â€» ì•„ë˜ context(ì—‘ì…€/ì›¹)ëŠ” ì°¸ê³ ë§Œ í•´ë„ ë˜ê³ ,
ë‚´ì¥ ì§€ì‹(2023ë…„ê¹Œì§€ í•™ìŠµ ë°ì´í„°, ê³µì‹ ì •ë³´ ë“±)ì´ ë” ì •í™•í•˜ë©´ ê·¸ê±¸ ìš°ì„ ìœ¼ë¡œ í™œìš©í•´ì„œ ë‹µë³€í•´.
ë‘˜ì´ ì¶©ëŒí•˜ë©´ ê³µì‹/ì •í™•ì„±/ìµœì‹ ì„±ì„ ë°˜ë“œì‹œ ìš°ì„ ì‹œ.
ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ë¶ˆí™•ì‹¤í•˜ë©´ â€œì •ë³´ ì—†ìŒâ€, â€œê³µì‹ ìœ„í‚¤/í¬í„¸ ì°¸ê³ â€ ë“±ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì•ˆë‚´í•´.
"""})

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=chat_history,
        temperature=0.7
    )

    def remove_undefined_items(text):
        return re.sub(r'^.*[\'"\[]?ë¯¸ì •[\]"\d\s\-:)]?.*\n?', '', text, flags=re.MULTILINE | re.IGNORECASE)

    def remove_placeholder_titles(text):
        return re.sub(r'^.*(ì‘í’ˆëª…\d+|ì„¤ëª…\d+).*\n?', '', text, flags=re.MULTILINE)

    raw_answer = response.choices[0].message.content.strip()
    clean_answer = remove_undefined_items(raw_answer)
    clean_answer = remove_placeholder_titles(clean_answer)
    return clean_answer

def is_recommendation_answer(gpt_answer):
    """
    1. ë¦¬ìŠ¤íŠ¸í˜• ì¶”ì²œ(1. 2. 3. ...ì´ ì—¬ëŸ¬ ë²ˆ ë“±ì¥)ë§Œ ì¶”ì²œ ë‹µë³€ìœ¼ë¡œ íŒë‹¨
    2. - (ëŒ€ì‹œ)ëŠ” ë¬´ì‹œ (ì¤„ê±°ë¦¬, íŠ¹ì„±, ìš”ì•½ ë“±ì—ë„ ì“°ì´ê¸° ë•Œë¬¸)
    """
    lines = gpt_answer.split("\n")
    number_list_count = sum(1 for l in lines if re.match(r"^\d+\.", l.strip()))
    # 2ê°œ ì´ìƒ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ ì¶”ì²œí˜•ìœ¼ë¡œ ë³¸ë‹¤
    return number_list_count >= 2

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¶”ì²œ í•¨ìˆ˜
import ast
import random
import json

def parse_to_list(val):
    """ë¬¸ìì—´ë¡œ ë„˜ì–´ì˜¨ ë¦¬ìŠ¤íŠ¸ë„ ì•ˆì „í•˜ê²Œ íŒŒì‹± (JSON/íŒŒì´ì¬ì‹/ë¹ˆê°’ ë‹¤ ëŒ€ì‘)"""
    if isinstance(val, list):
        return val
    if val is None or val == "":
        return []
    if isinstance(val, str):
        val = val.strip()
        if val.startswith("[") and val.endswith("]"):
            try:
                return ast.literal_eval(val)
            except Exception:
                try:
                    return json.loads(val)
                except Exception:
                    return []
        elif "," in val:
            return [v.strip() for v in val.split(",") if v.strip()]
        else:
            return [val]
    return []

def get_multilang(meta, field, lang="ko", fallback_order=None):
    fallback_order = fallback_order or ["ko", "en", "es"]
    order = [lang] + [l for l in fallback_order if l != lang]
    # íƒ€ì´í‹€ì€ íŠ¹ì´í•˜ê²Œ ì²˜ë¦¬: ko/romaji/esë§Œ ì‚¬ìš©
    if field == "title":
        if lang == "ko":
            return meta.get("title_ko", "")
        elif lang == "es":
            return meta.get("title_es", "")
        else:
            return meta.get("title_romaji", "")
    for l in order:
        key = f"{field}_{l}"
        if key in meta and meta[key]:
            v = meta[key]
            return parse_to_list(v) if field == "genres" else v
    return [] if field == "genres" else ""

# ë‹¤êµ­ì–´ ì¶”ì²œ ì´ìœ  ì…‹íŒ…
RECOMMEND_REASON = {
    "ko": [
        "ë„ˆì˜ ì• ë‹ˆë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ì‘í’ˆë“¤ ì·¨í–¥ì„ ë³´ë‹ˆê¹Œ ì´ê²Œ ë”±ì´ì•¼.",
        "ìµœê·¼ì— ë³¸ ì• ë‹ˆë‘ ì¥ë¥´ê°€ ë¹„ìŠ·í•´ì„œ ì¶”ì²œí•´!",
        "ë„ˆê°€ ì¢‹ì•„í•˜ëŠ” í…Œë§ˆë‘ ì˜ ì–´ìš¸ë¦´ ê±°ì•¼.",
        "ë¹„ìŠ·í•œ ë¶„ìœ„ê¸°ì˜ ì‘í’ˆì´ë¼ì„œ ê³¨ë¼ë´¤ì–´.",
        "ë„¤ê°€ ìì£¼ ë³¸ ì¥ë¥´ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí–ˆì–´.",
        "ë„¤ ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí–ˆì–´! ì¬ë°Œê²Œ ë³¼ ìˆ˜ ìˆì„ ê±°ì•¼.",
        "ì´ëŸ° ì¥ë¥´ ì¢‹ì•„í•˜ì–ì•„? ê·¸ë˜ì„œ ì¶”ì²œí•´.",
        "ìµœê·¼ ë„¤ê°€ ë³¸ ì‘í’ˆë“¤ê³¼ ê´€ë ¨ëœ ì• ë‹ˆì•¼!",
        "ì·¨í–¥ ë¶„ì„í•´ì„œ ì œì¼ ì˜ ë§ì„ ê²ƒ ê°™ì€ ì‘í’ˆì´ì•¼.",
    ],
    "en": [
        "This one fits your anime list perfectly.",
        "Recommended because it has similar genres to your recent favorites.",
        "It matches the themes you often enjoy.",
        "Picked this because the vibe is similar to what you like.",
        "Based on the genres you watch most.",
        "Recommended from your list! Youâ€™ll probably enjoy it.",
        "You seem to like this kind of genre, so here you go!",
        "This anime is related to what you recently watched.",
        "Analyzed your favorites and picked the best match.",
    ],
    "es": [
        "Â¡Esta serie encaja perfectamente con tu lista de anime!",
        "Te la recomiendo porque tiene gÃ©neros similares a los que sueles ver.",
        "Va con los temas que disfrutas normalmente.",
        "ElegÃ­ esta porque el ambiente es parecido a tus favoritos.",
        "Basado en los gÃ©neros que mÃ¡s ves.",
        "Â¡Recomendado segÃºn tu lista! Seguro que te gustarÃ¡.",
        "SÃ© que te gusta este tipo de gÃ©nero, asÃ­ que aquÃ­ tienes.",
        "Este anime estÃ¡ relacionado con los que viste recientemente.",
        "AnalicÃ© tus favoritos y elegÃ­ la mejor opciÃ³n para ti.",
    ],
}

# ì¶”ì²œ ì´ìœ  ëœë¤ ë°˜í™˜
def get_recommend_reason(user_language, main_genre):
    comment_set = RECOMMEND_REASON.get(user_language, RECOMMEND_REASON["ko"])
    return random.choice(comment_set).format(main_genre=main_genre)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¶”ì²œ ì• ë‹ˆë©”ì´ì…˜ í•¨ìˆ˜
def recommend_anime_by_userlist(
    user_anime_titles, user_language="ko", top_k=3, with_detail=True,
    exclude_tags=None, exclude_genres=None
):
    exclude_tags = exclude_tags or []
    exclude_genres = exclude_genres or []

    print(f"\n[ì¶”ì²œ] ìœ ì €ê°€ ë³¸ ì• ë‹ˆ: {user_anime_titles}")
    print(f"[ì¶”ì²œ] ìš”ì²­ ì–¸ì–´: {user_language} / top_k: {top_k}")

    user_features = []
    user_genres_counter = {}
    user_tags_counter = {}

    for title in user_anime_titles:
        docs = reco_vectordb.similarity_search(title, k=1)
        if docs:
            meta = docs[0].metadata
            user_features.append(docs[0].page_content)
            genres = parse_to_list(meta.get("genres_en", []))  # ì¥ë¥´ í†µê³„ëŠ” ì˜ì–´ ê¸°ì¤€
            tags = parse_to_list(meta.get("tags", []))
            print(f" - '{title}' -> genres: {genres} / tags: {tags}")
            for g in genres:
                user_genres_counter[g] = user_genres_counter.get(g, 0) + 1
            for t in tags:
                user_tags_counter[t] = user_tags_counter.get(t, 0) + 1

    if not user_features:
        print("[ì¶”ì²œ] ìœ ì € ì• ë‹ˆ ë²¡í„° ì¶”ì¶œ ì‹¤íŒ¨")
        return []

    top_user_genres = set(sorted(user_genres_counter, key=user_genres_counter.get, reverse=True)[:5])
    top_user_tags = set(sorted(user_tags_counter, key=user_tags_counter.get, reverse=True)[:7])
    print(f"[ì¶”ì²œ] top_user_genres: {top_user_genres} / top_user_tags: {top_user_tags}")

    query = " ".join(user_features)
    candidates = reco_vectordb.similarity_search(query, k=top_k + 50)
    print(f"[ì¶”ì²œ] í›„ë³´ ì‘í’ˆ ìˆ˜: {len(candidates)}")

    already_seen = set([t.strip().lower() for t in user_anime_titles])
    result = []

    # main_genre = ë§ì´ ë³¸ ì¥ë¥´ ì¤‘ í•˜ë‚˜ (ì—†ìœ¼ë©´ "ì¶”ì²œ" ê¸°ë³¸ê°’)
    main_genre = next(iter(top_user_genres), "ì¶”ì²œ")
    recommend_reason = get_recommend_reason(user_language, main_genre)

    filtered_candidates = []
    for doc in candidates:
        meta = doc.metadata
        titles = [
            meta.get("title_ko", ""), meta.get("title_romaji", ""),
            meta.get("title_native", ""), meta.get("title_es", "")
        ]
        if any(t.strip().lower() in already_seen for t in titles if t):
            continue

        genres = set(parse_to_list(meta.get("genres_en", [])))
        tags = set(parse_to_list(meta.get("tags", [])))

        if exclude_genres and any(x in genres for x in exclude_genres):
            continue
        if exclude_tags and any(x in tags for x in exclude_tags):
            continue

        genre_match = len(top_user_genres & genres)
        tag_match = len(top_user_tags & tags)
        if genre_match == 0 and tag_match == 0:
            continue

        score = 1.0 + 0.7 * genre_match + 0.5 * tag_match
        filtered_candidates.append((score, meta))

    print(f"[ì¶”ì²œ] í•„í„° í›„ í›„ë³´: {len(filtered_candidates)}")

    filtered_candidates.sort(key=lambda x: -x[0])

    for score, meta in filtered_candidates:
        # íƒ€ì´í‹€/ì„¤ëª…/ì¥ë¥´: ë‹¤êµ­ì–´ ìë™ fallback
        title = get_multilang(meta, "title", user_language)
        description = get_multilang(meta, "description", user_language)
        genres = get_multilang(meta, "genres", user_language)
        cover = meta.get("cover_image_l", meta.get("cover_image", "")) or ""
        year = meta.get("start_year", None)
        format_ = meta.get("format", "")
        studio_objs = parse_to_list(meta.get("studios", []))
        studio_names = [s['node']['name'] for s in studio_objs if isinstance(s, dict) and 'node' in s and 'name' in s['node']]

        if with_detail:
            result.append({
                "title": title,
                "description": description,
                "cover_image": cover,
                "year": year,
                "genres": genres,
                "studios": studio_names,
                "format": format_,
                "reco_score": round(score, 4),
                "recommend_reason": recommend_reason,
            })
        else:
            result.append(title)
        if len(result) >= top_k:
            break

    print(f"[ì¶”ì²œ] ìµœì¢… ì¶”ì²œ result: {result[:3]} ... [ì´ {len(result)}ê°œ]")
    return result
