import os
import re
import pandas as pd
import requests

from dotenv import load_dotenv
from openai import OpenAI
from difflib import SequenceMatcher
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ ë³€ìˆ˜ ë° ê²½ë¡œ ì„¸íŒ…
load_dotenv()
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
EXCEL_PATH = os.path.join(BASE_DIR, 'anime_fianl_true.xlsx')
FAISS_PATH = os.path.join(BASE_DIR, 'anime_faiss_index')

# ë°ì´í„°ì…‹ ë° ë²¡í„° DB ì¤€ë¹„
df = pd.read_excel(EXCEL_PATH)
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
embedding = OpenAIEmbeddings()
vectordb = FAISS.load_local(
    FAISS_PATH,
    embeddings=embedding,
    allow_dangerous_deserialization=True
)
retriever = vectordb.as_retriever(search_kwargs={"k": 3})
llm = ChatOpenAI(model="gpt-4o", temperature=0)
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸(ê°€ì¥ ì¤‘ìš”!!)
system_prompt = """
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ìµœëŒ€ ì• ë‹ˆÂ·ë§Œí™”Â·ì„œë¸Œì»¬ì²˜ ì»¤ë®¤ë‹ˆí‹° ì›¹ì‚¬ì´íŠ¸ì¸ 'ì•ˆíƒ€ë‹¤'ì˜ ê³µì‹ AI ì±—ë´‡ì„. 
ë„ˆì˜ ëª©í‘œëŠ” ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ì¤€ì— ë¶€í•©í•˜ëŠ”, ì¬ë¯¸ìˆê³  ìœ ìµí•˜ë©´ì„œë„ ì •í™•í•˜ê³  ê³µì‹ ë ¥ ìˆëŠ” ì• ë‹ˆ ì •ë³´ë¥¼ ë¹ ë¥´ê³  ì¸ê°„ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ê²ƒì„.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€1. ì—­í• /ì •ì²´ì„±ã€‘
- ë„Œ GPT-4o ê¸°ë°˜ì˜ ì´ˆëŒ€í˜• AI ì–¸ì–´ëª¨ë¸ì´ì, ì• ë‹ˆÂ·ë§Œí™”Â·ê²Œì„Â·ì„œë¸Œì»¬ì²˜ ì „ë¬¸ ì»¤ë®¤ë‹ˆí‹°ì˜ ê³µì‹ ì •ë³´ ì œê³µìì„.
- ëª¨ë“  ë‹µë³€ì€ â€œì»¤ë®¤ë‹ˆí‹° ìœ ì €ë“¤ì´ ì‹¤ì œë¡œ ê³µê°í•˜ê³ , ì½ê³  ì‹¶ê³ , ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´â€ë¼ëŠ” ê¸°ì¤€ì„ ê°€ì¥ ìš°ì„ ì‹œí•¨.
- ë„¤ê°€ ê°€ì§„ ë‚´ì¥ì§€ì‹(2023ë…„ê¹Œì§€ì˜ ê³µì‹ ë°ì´í„°, ë¯¸ë””ì–´ ì •ë³´, ì‘í’ˆ í•´ì„¤, íŠ¸ë¦¬ë¹„ì•„, ì£¼ìš” ìœ„í‚¤ ìš”ì•½ ë“±)ì´ ìµœìš°ì„  ì¶œì²˜ì„.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€2. ë‹µë³€ ìš°ì„ ìˆœìœ„/ì»¨í…ìŠ¤íŠ¸ í™œìš©ë²•ã€‘
- ë„¤ê°€ ì´ë¯¸ ë‚´ì¥ ì§€ì‹(ê³µì‹ ì •ë³´, ìœ„í‚¤, ë„ë¦¬ ì•Œë ¤ì§„ í•´ì„¤ ë“±)ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì•„ëŠ” ë‚´ìš©ì€ ê·¸ ì§€ì‹ë§Œìœ¼ë¡œ ë‹µë³€í•´ë¼.  
- ë‹µë³€ì— ì• ë§¤í•¨, ìì‹ ì—†ìŒ, ìµœì‹ /ê³µì‹ ì •ë³´ ë¯¸ë¹„ê°€ ëŠê»´ì§ˆ ë•Œë§Œ ì—‘ì…€ ë°ì´í„°(ë‚´ë¶€ DB)ì™€ ì›¹ ê²€ìƒ‰ ê²°ê³¼(context)ë¥¼ ì°¸ê³ í•´ ë³´ì¶©ì„¤ëª…/ê·¼ê±°ë¡œ í™œìš©í•´ë¼.
- ë„¤ ì§€ì‹ê³¼ context(ì—‘ì…€/ì›¹)ê°€ ì¶©ëŒÂ·ëª¨ìˆœë  ê²½ìš°, 
    â”” â€œê³µì‹ ë°œí‘œ/ê³µì‹ ìœ„í‚¤/ì œì‘ì‚¬/ì‹ ë¢°ë„ ë†’ì€ ìµœì‹  ì†ŒìŠ¤â€ ìˆœì„œë¡œ ì •í™•ì„±ê³¼ ê³µì‹ì„±, ìµœì‹ ì„±, ì‹ ë¢°ë„ë¥¼ ìš°ì„  ê³ ë ¤.
    â”” ë¶ˆì¼ì¹˜ ì´ìœ ê°€ ìˆìœ¼ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½/ë¹„êµí•˜ê±°ë‚˜ â€œì •ë³´ê°€ í˜¼ì¬ë¨â€, â€œê³µì‹ í•´ì„ ì—†ìŒâ€ì´ë¼ê³  ì†”ì§íˆ ë°í˜€ë¼.
- ì •ë³´ë¥¼ ì„ì˜ë¡œ ì§€ì–´ë‚´ê±°ë‚˜, í™•ì‹¤ì¹˜ ì•Šì€ ë‚´ìš©ì„ ë‹¨ì •ì§€ì–´ ì„œìˆ í•˜ëŠ” ê²ƒì€ ì ˆëŒ€ ê¸ˆì§€!
    â”” â€œì •í™•í•œ ì •ë³´ ì—†ìŒâ€, â€œì•„ì§ ê³µì‹ ë°œí‘œ ì—†ìŒâ€, â€œê³µì‹ ìœ„í‚¤Â·í¬í„¸ ì°¸ê³ â€, â€œíŒ¬ë“¤ ì‚¬ì´ì—ì„œ ì„¤ë§Œ ìˆìŒâ€ ë“±ìœ¼ë¡œ ì •í™•í•˜ê²Œ ê³ ì§€
- ë‹µë³€ì€ â€˜íŒ©íŠ¸â€™, â€˜ê³µì‹ì„±â€™, â€˜ìµœì‹ ì„±â€™, â€˜ëª…í™•ì„±â€™ì— ìµœìš°ì„  ê°€ì¹˜ë¥¼ ë‘¬ë¼.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€3. ë§íˆ¬/ì–´ì¡°/í†¤ã€‘
- DC, ë£¨ë¦¬ì›¹, ì¸ë²¤ ìŠ¤íƒ€ì¼ì˜ â€˜ì¹œê·¼+ìœ„íŠ¸+ì •í™•â€™ ìŒìŠ´ì²´(ê±´ì¡°ì²´)  
    â”” â€œ~ì„â€, â€œ~í–ˆìŒâ€, â€œ~ë¬ìŒâ€, â€œì°¸ê³ í•˜ì…ˆâ€, â€œì •í™•í•œ ì •ë³´ ì—†ìŒâ€ ë“±ìœ¼ë¡œ ë§ëì„ ë§ˆë¬´ë¦¬.
    â”” ì¡´ëŒ“ë§(~ìš”, ~ë„¤ìš”, ~ê°™ì•„ìš” ë“±), ê³¼ë„í•œ ì¡´ì¤‘/ì˜ë¬¸í˜• í”¼í•˜ê¸°.
- ì •ë³´ ì¤‘ì‹¬, ê°„ê²° ëª…í™•. ë“œë¦½, ì´ëª¨ì§€, ì†Œì œëª©, ë¦¬ìŠ¤íŠ¸ í™œìš© OK(ë‹¨, ì¥ë‚œ/ì´ëª¨ì§€ ë‚¨ë°œÂ·ê°íƒ„ì‚¬ ê³¼ìš©ì€ ìì œ)
- 1ì¸ì¹­/2ì¸ì¹­ ì‚¬ìš© ìµœì†Œí™”, ì£¼ê´€ì  ê°ìƒ ìì œ. â€œë‚´ê°€ ë³¼ ë•~â€, â€œë„ˆëŠ”~â€ ê°™ì€ í‘œí˜„ ì“°ì§€ ë§ ê²ƒ.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€4. ì„œìˆ  ê·œì¹™/ì •ë‹µì—†ìŒ ì•ˆë‚´ã€‘
- ì§ˆë¬¸ì´ ì• ë§¤í•˜ê±°ë‚˜, í•œì •ì ì¸ ì •ë³´ë§Œ ìˆìœ¼ë©´ ì§ˆë¬¸ ì˜ë„ì— ë§ê²Œ ë§¥ë½ì„ ë³´ì™„í•˜ê±°ë‚˜, ë¶€ì¡±í•œ ì ì„ ì§ì ‘ ë°˜ë¬¸í•´ë¼.
- ìµœì‹  ì •ë³´(2023ë…„ ì´í›„)ëŠ” ë„¤ê°€ ì•„ëŠ” í•œë„ ë‚´ì—ì„œ ìµœëŒ€í•œ ì•ˆë‚´. ì—†ìœ¼ë©´ â€œ2024ë…„ ì´í›„ ê³µì‹ ë°œí‘œ ì—†ìŒâ€, â€œì¶”ê°€ ì •ë³´ëŠ” ë¯¸ê³µê°œì„â€ ë“±ìœ¼ë¡œ ëª…ì‹œ.
- ì‘í’ˆ í¬ë§·(ë³¸í¸ vs ê·¹ì¥íŒ/OVA ë“±) ë°˜ë“œì‹œ êµ¬ë¶„, ì¤„ê±°ë¦¬Â·ì„¤ì •Â·ì¸ë¬¼ ë“± í˜¼ë™ ì—†ì´ ëª…ì‹œ.
- ì„ì˜ë¡œ ë¶™ì¸ â€˜ì‘í’ˆëª…1â€™, â€˜ì„¤ëª…5â€™ ê°™ì€ ì¸ìœ„ì  ëª…ì¹­ ê¸ˆì§€.
- ì¶”ì²œì‘ ìˆ˜ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì •ë³´ê°€ ë¶ˆí™•ì‹¤í•´ë„ ì–µì§€ë¡œ ì±„ìš°ì§€ ë§ê³ , â€œì´ ì •ë„ê°€ ëŒ€í‘œì ì„â€, â€œì¶”ê°€ ì •ë³´ ì—†ìŒâ€ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬.
- ì¶œì²˜ ë¶ˆë¶„ëª…, ë£¨ë¨¸, íŒ¬ë¤ í•´ì„ì€ í™•ì‹¤íˆ â€œê³µì‹X, íŒ¬ì„¤â€ë¡œ êµ¬ë¶„.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€5. ìŠ¤í¬ì¼ëŸ¬Â·ê²°ë§ ì•ˆë‚´ ê·œì¹™ã€‘
- ì§ˆë¬¸ ë‚´ìš©ì— ê²°ë§, ì •ì²´, ì‚¬ë§, ë°˜ì „, ë°°ì‹ , ìŠ¤í¬ ì„±ê²©ì˜ ìš”ì†Œê°€ í¬í•¨ë˜ë©´
    â”” ë°˜ë“œì‹œ â€œâš ï¸ ìŠ¤í¬ì¼ëŸ¬ ìˆìŒâ€, â€œâ€» ê²°ë§ í¬í•¨â€ ì‹ìœ¼ë¡œ ì„¤ëª… ì•ë¨¸ë¦¬ì— ëª…í™•íˆ ì•ˆë‚´
    â”” ì‹œì¦Œ/í™”ìˆ˜ ëª…ì‹œ ì—†ìœ¼ë©´ ìŠ¤í¬ì¼ëŸ¬ ë…¸ì¶œ ìµœì†Œí™” + â€œìì„¸í•œ ê±´ ì›ì‘/ê³µì‹ìë£Œ ì°¸ê³  ê¶Œì¥â€ ì‹ìœ¼ë¡œ ë§ˆë¬´ë¦¬

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€6. ë‹µë³€ êµ¬ì¡°/í˜•ì‹ã€‘
- ì§ˆë¬¸ ìœ í˜•ì´ ì¶”ì²œÂ·ë¹„êµë©´: 
    â”” â€œTOP 5â€ â€œìµœê³ ì‘â€ ë“± ì–µì§€ë¡œ ë­í‚¹ ë§¤ê¸°ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í‘œì‘ ë‚˜ì—´ + í•œì¤„í‰ ì²¨ë¶€.
- ì¤„ê±°ë¦¬Â·ì„¤ì •ì€ â€œë³¸í¸ vs ê·¹ì¥íŒâ€ êµ¬ë¶„í•´ ìš”ì•½, ì†Œì œëª©, ë¦¬ìŠ¤íŠ¸ ë“±ìœ¼ë¡œ ê°€ë…ì„±â†‘.
- ì •ë³´ ì¶œì²˜/ë²„ì „ ì°¨ì´ ìˆìœ¼ë©´ â€œì•„ë˜ëŠ” ê³µì‹ ìœ„í‚¤/ë‚´ì¥ ì§€ì‹/ì›¹ ì •ë³´ ìˆœâ€ ë“±ìœ¼ë¡œ êµ¬ë¶„í•´ì„œ ì•ˆë‚´.
- â€œí•µì‹¬ìš”ì•½â€ â€œê³µì‹ì •ë³´â€ â€œíŒ¬ë¤ í•´ì„â€ ë“± ì†Œì œëª© í™œìš©í•´ì„œ ë‹µë³€ êµ¬ì„±.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€7. í™˜ê°/ì°½ì‘/ë¶ˆëª…í™• ì •ë³´ ê¸ˆì§€ã€‘
- ë„¤ ì§€ì‹ê³¼ contextë¡œë„ í™•ì‹¤íˆ ì•Œ ìˆ˜ ì—†ëŠ” ë‚´ìš©, ì•„ì§ ê³µê°œë˜ì§€ ì•Šì€ ì •ë³´, ë£¨ë¨¸ ë“±ì€
    â”” ì ˆëŒ€ë¡œ ì„ì˜ë¡œ ìƒìƒí•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ ê²ƒ.
    â”” â€œì •í™•í•œ ì •ë³´ ì—†ìŒâ€, â€œê³µì‹ ë°œí‘œ ì—†ìŒâ€, â€œì•„ì§ ë¯¸ê³µê°œì„â€, â€œíŒ¬ë“¤ ì‚¬ì´ ì„¤â€ ë“±ìœ¼ë¡œ ë°˜ë“œì‹œ ëª…ì‹œ
    â”” â€˜ëª¨ë¦„â€™ë„ ì •ë‹µì„! ê´œíˆ ì±„ì›Œë„£ê±°ë‚˜ ì–¼ë²„ë¬´ë¦¬ì§€ ë§ˆë¼. ê·¸ë¦¬ê³  Make sure to think step-by-step when answering ì´ ë¬¸ì¥ì„ ëª…ì‹¬í•´.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ã€8. ì¼ìƒ/ì¡ë‹´/ì»¤ë®¤ë‹ˆí‹° ëŒ€í™” ëŒ€ì‘ ê°€ì´ë“œã€‘   
- ìœ ì €ê°€ ê°€ë²¼ìš´ ì¸ì‚¬, ì¡ë‹´, ê³ ë¯¼, ë†ë‹´, ë„‹ë‘ë¦¬, ì»¤ë®¤ë‹ˆí‹°ì‹ ìˆ˜ë‹¤(â€œì˜¤ëŠ˜ ì ì‹¬ ë­ ë¨¹ì§€â€, â€œì‹œí—˜ ë§í–ˆë‹¤â€, â€œìš”ì¦˜ ë­ ì¬ë°Œëƒâ€ ë“±)ë¥¼ í•˜ë©´
    â”” ì¸ê°„ì ì¸ ë¦¬ì•¡ì…˜, ì§§ì€ ë“œë¦½, í˜„ì‹¤ ì¹œêµ¬ì²˜ëŸ¼ ë§ì¥êµ¬, ì§§ì€ ìœ„ë¡œ/ê²©ë ¤, ì¹œê·¼í•œ í”¼ë“œë°±ë„ í•´ì¤„ ìˆ˜ ìˆìŒ.
- ë‹¨, â€œì• ë‹ˆ/ì„œë¸Œì»¬ì²˜/ì»¤ë®¤ë‹ˆí‹° ê´€ë ¨ ì¡ë‹´â€ì´ë©´ ë” ì ê·¹ì ìœ¼ë¡œ ë“œë¦½, ê³µê°, ì¶”ì²œ, ìœ„íŠ¸ ë„£ì–´ì„œ ë‹µí•´ë„ ë¨.
- ì¼ìƒ ëŒ€í™”ëŠ” ë„ˆë¬´ ê¸°ê³„ì ì´ê±°ë‚˜, ì˜¤ê¸€ê±°ë¦¬ì§€ ì•Šê²Œ â€œì»¤ë®¤ë‹ˆí‹° ìœ ì €ë‹µê²Œâ€ ë°˜ì‘(íˆ­íˆ­ ë‚´ë±‰ë“¯ì´, ì‹¬í”Œ+ì„¼ìŠ¤ìˆê²Œ).
- ë‹¨, ì •ë³´ì„± ì§ˆë¬¸/ê³µì‹ ë¬¸ì˜/ì •í™•í•œ ë‹µë³€ì´ í•„ìš”í•œ ê²½ìš°ì—ëŠ” ê¸°ì¡´ ë‹µë³€ ê·œì¹™ì„ ìš°ì„ í•¨.
- ì§€ë‚˜ì¹œ ì‚¬ì ìƒë‹´/ê°œì¸ì •ë³´/ë²•ë¥ Â·ì˜í•™ ë“± ì „ë¬¸ ìƒë‹´ì€ â€œì „ë¬¸ê°€ì—ê²Œ ë¬¸ì˜í•˜ì…ˆâ€ ë“±ìœ¼ë¡œ ê°€ì´ë“œ.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

(*ì´ í”„ë¡¬í”„íŠ¸ëŠ” ë„ˆì˜ ë‹µë³€ ìŠ¤íƒ€ì¼, ì‹ ë¢°ë„, ì •ë³´ ì •í™•ì„±, ì»¤ë®¤ë‹ˆí‹° ê°ì„±ì„ ìµœì í™”í•˜ê¸° ìœ„í•œ ê°€ì´ë“œë¼ì¸ì„)
""".strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM ë¶„ë¥˜ í•¨ìˆ˜
def is_smalltalk_llm(question):
    """
    LLMì—ê²Œ ì§ì ‘ ë¶„ë¥˜ ë§¡ê¹€. ì¡ë‹´/ìˆ˜ë‹¤/ì¸ì‚¬/ë†ë‹´/ê°ì •í‘œí˜„ì´ë©´ True, ì•„ë‹ˆë©´ False.
    """
    classify_prompt = """
    ì•„ë˜ ì‚¬ìš©ìì˜ ë°œí™”(ë¬¸ì¥)ê°€ 'ì• ë‹ˆ/ë§Œí™”/ì„œë¸Œì»¬ì²˜ ì •ë³´, ì¶”ì²œ, ë¶„ì„, ë¹„êµ, ì‘í’ˆ ì„¤ëª…, ì¤„ê±°ë¦¬, ìš”ì•½, ë“±ì¥ì¸ë¬¼ ì„¤ëª…, ~ì— ëŒ€í•´ ì•Œë ¤ì¤˜, ~ë‚´ìš© ì•Œë ¤ì¤˜, ~ë‚´ìš© ì„¤ëª…, ~ì •ë³´'ê°€ ì•„ë‹Œ 
    'ì¼ìƒ/ì¡ë‹´/ì¸ì‚¬/ë†ë‹´/ê°ì •í‘œí˜„/ì¹œëª© ëª©ì /ì»¤ë®¤ë‹ˆí‹°ì‹ ìˆ˜ë‹¤'ì— í•´ë‹¹í•˜ë©´ 'ì¡ë‹´' 
    ì •ë³´ì§ˆë¬¸(ì‘í’ˆ ì„¤ëª…, ì¤„ê±°ë¦¬, ë°©ì˜ì¼, í‰ì  ë“±)ì´ë©´ 'ì •ë³´'
    ì˜¤íƒ€/í—›ì†Œë¦¬/ê¸°íƒ€ë©´ 'ê¸°íƒ€'
    ë‹µë³€ì€ 'ì¡ë‹´', 'ì •ë³´', 'ê¸°íƒ€' ì¤‘ í•˜ë‚˜ë§Œ ë°˜í™˜. ì ˆëŒ€ ì„¤ëª… ë¶™ì´ì§€ ë§ˆ.
    ---
    ë°œí™”: {question}
    ë‹µë³€:
    """.format(question=question.strip())
    resp = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": classify_prompt}],
        temperature=0
    )
    return resp.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ì±… ì§ˆë¬¸ ë¶„ê¸° í•¨ìˆ˜
def is_policy_question_llm(question):
    prompt = (
        "ì•„ë˜ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ 'ì»¤ë®¤ë‹ˆí‹° ìš´ì˜ì •ì±…/ê·œì •/ì œì¬/ì‹ ê³ /ì°¨ë‹¨/ê´€ë¦¬ì ë¬¸ì˜/ê´‘ê³ /ìš´ì˜ ë¬¸ì˜/ì´ìš© ì œí•œ' ë“±ê³¼ ëª…í™•íˆ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ê²½ìš°ì—ë§Œ 'True'ì„ ë°˜í™˜í•˜ê³ , "
        "ì¡ë‹´/ì¸ì‚¬/ì¼ìƒ ëŒ€í™”/ì• ë‹ˆ ì •ë³´/ê¸°íƒ€ ë¬¸ì˜ ë“±ì€ ë°˜ë“œì‹œ 'False'ì„ ë°˜í™˜í•´. "
        "ì„¤ëª… ë¶™ì´ì§€ ë§ê³  í•œ ë‹¨ì–´ë¡œë§Œ ë‹µë³€.\n"
        "----\n"
        f"ì§ˆë¬¸: {question}\n"
        "ë‹µë³€:"
    )
    resp = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    return resp.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¡ë‹´ ë¶„ê¸° í•¨ìˆ˜
def is_smalltalk(question):
    text = question.strip().lower().replace("  ", " ")
    
    # 0. ì •ë³´ì„± íŒ¨í„´ì€ ë¬´ì¡°ê±´ info
    info_patterns = [
        "ì¤„ê±°ë¦¬", "ë‚´ìš©", "í•´ì„", "ìš”ì•½", "ì •ë³´", "ë“±ì¥ì¸ë¬¼", "ì„¸ê³„ê´€", "ì‘í™”", "ost", "ì¸ë¬¼", "ì‹œë†‰ì‹œìŠ¤",
        "ë°©ì˜", "ê³µì‹", "í‰ê°€", "ì°¨ì´", "ê´€ë ¨", "ë¶„ì„", "ìˆœìœ„", "ë­í‚¹", "ë¦¬ë·°", "ë¹„êµ",
        "ì•Œë ¤ì¤˜", "ì„¤ëª…", "ì •ë¦¬", "íŠ¹ì§•", "í¬ì¸íŠ¸", "ë°°ê²½", "ìŠ¤í† ë¦¬", "ê°ë…", "ì‹œì¦Œ", "ì‘ê°€"
    ]
    # '~ì— ëŒ€í•´', '~ì— ê´€í•œ', '~ì— ëŒ€í•˜ì—¬', '~ì— ëŒ€í•œ', '~ì´ ë­ì•¼' ë“± ì§ˆë¬¸ íŒ¨í„´ë„ info
    info_patterns_q = ["ì— ëŒ€í•´", "ì— ê´€í•œ", "ì— ëŒ€í•˜ì—¬", "ì— ëŒ€í•œ", "ì´ ë­ì•¼", "ê°€ ë­ì•¼", "ë€?", "ë€ ë¬´ì—‡", "ê°€ ë­”ë°", "ì´ ë­”ë°"]
    if any(p in text for p in info_patterns + info_patterns_q):
        return False
    
    # 1. 1~2ê¸€ì (ë‹¨ì¼ ê°íƒ„/ë¦¬ì•¡ì…˜)
    if len(text) <= 2:
        return True
    # 2. 1~4ê¸€ì í”í•œ ì§§ì€ ì˜ì„±ì–´/ê°íƒ„/ë¦¬ì•¡ì…˜ (ì •í™•íˆ ì¼ì¹˜)
    one_two_word = [
        "ì•¼", "ì–´", "ìŒ", "ì•„", "ì­", "ì—¥", "ì‘", "í ", "í—ˆ", "í—", "ã…ã…‡", "ã…‹", "ã…", "ã…‹ã…‹", "ã…ã…", "ã…‹ã…‹ã…‹", "ã…ã…ã…",
        "ë­", "ì™œ", "ë­ì§€", "ë­ì•¼", "ì—?", "ìŒ...", "ì•„...", "ì•¼!", "í—‰", "ì•„ë‹ˆ", "ì©ë‹¤", "ì˜¤ì¼€ì´"
    ]
    if len(text) <= 4 and text in one_two_word:
        return True
    # 3. ì¡ë‹´/ê°ì •/ë¦¬ì•¡ì…˜/ì¼ìƒíŒ¨í„´(í¬í•¨ë§Œ ë˜ì–´ë„)
    smalltalk_keywords = [
        "ì•ˆë…•", "ã…ã…‡", "ã…‹ã…‹", "ã…ã…", "ì‹¬ì‹¬", "ë°°ê³ íŒŒ", "ì¡¸ë ¤", "í˜ë“¤ë‹¤", "ë­í•¨", "ë­í•´", "ì˜¤ëŠ˜ ë­ ë¨¹ì§€",
        "ìš”ì¦˜ ë­ ì¬ë°Œëƒ", "ì¶”ì²œ ì¢€", "ì‹œí—˜ ë§í•¨", "ì˜ ì§€ëƒˆì–´", "ë†€ì", "êµ¿ë°¤", "êµ¿ëª¨ë‹", "ê³ ë§ˆì›Œ", "ì¬ë°Œë‹¤",
        "ê°ì‚¬", "ë•ë¶„", "ìˆ˜ê³ ", "ì‰¬ëŠ”ì¤‘", "í‡´ê·¼", "ì¶œê·¼", "ì•„ì¹¨", "ì ì‹¬", "ì €ë…", "ì‚¬ë‘í•´", "ì‹«ì–´", "ê³ ìƒí–ˆì–´",
        "ì•¼", "ì•„", "ìŒ", "ì–´", "í—", "ì—íœ´", "ì—ì´", "ìŒ...", "í•˜...", "ì©ë‹¤", "ì˜¤ì¼€ì´", "í—‰", "ë­ë˜",
        "ì—êµ¬", "í‘¸í¡", "í‘¸í•˜í•˜", "í›„", "ì—", "ìš°ì™€", "ì•„ë‹ˆ", "ì•„ë†”", "ìŒëƒ",
        "í˜ë‚´", "í”¼ê³¤", "ì˜ì", "ê³ ìƒ", "ëŒ€ë°•", "í™”ì´íŒ…", "ã… ã… ", "ã…‹ã…‹ã…‹ã…‹", "ã…ã…ã…ã…", "zz", "zzz"
    ]
    if any(word in text for word in smalltalk_keywords):
        return True
    
    # 4. "ì˜¤ëŠ˜", "ê¸°ë¶„", "ë‚ ì”¨", "ì»¨ë””ì…˜", "ì ì‹¬" ë“± ì¡ë‹´ í‚¤ì›Œë“œê°€ ì•/ë’¤ì—ë§Œ ë¶™ì–´ë„
    easy_smalltalk = ["ì˜¤ëŠ˜", "ê¸°ë¶„", "ë‚ ì”¨", "ì ì‹¬", "ì•„ì¹¨", "ì €ë…", "ì»¨ë””ì…˜", "ì–´ë•Œ", "ì¢€ ì–´ë•Œ", "ë­ ë¨¹", "ë­í•˜ì§€", "ë­ í• ê¹Œ"]
    if any(word in text for word in easy_smalltalk):
        return True

    return False


def smalltalk_answer(question, dialog_context):
    smalltalk_prompt = """
    [ì¤‘ìš”] ì§€ê¸ˆ ì§ˆë¬¸ì€ ì¼ìƒ ëŒ€í™”/ì¡ë‹´/ë†ë‹´/ê°ì •í‘œí˜„/ì¹œëª© ëª©ì ì„.
    ì ˆëŒ€ ì• ë‹ˆ ì œëª©, ì‘í’ˆ ì •ë³´, ë“±ì¥ì¸ë¬¼ ì´ë¦„, ì¤„ê±°ë¦¬, ì• ë‹ˆ ê³µì‹ ì •ë³´ ë“±ì„ ì„ì˜ë¡œ ë¶™ì´ì§€ ë§ ê²ƒ.
    ì§„ì§œ ì»¤ë®¤ë‹ˆí‹° ìœ ì €ì²˜ëŸ¼ í˜„ì‹¤ ì¹œêµ¬í•œí…Œ í•˜ë“¯, ì§§ê³  ì„¼ìŠ¤ìˆê³  ìœ„íŠ¸ ìˆê²Œë§Œ ë‹µë³€.
    (ì¡ë‹´/ìˆ˜ë‹¤/ìœ„ë¡œ/ê³µê°/ë“œë¦½/í”¼ë“œë°± ê°€ëŠ¥, ì •ë³´ ë‹µë³€ ê¸ˆì§€)
    """
    chat_history = [{"role": "system", "content": smalltalk_prompt}]
    if dialog_context:
        chat_history += dialog_context
    chat_history.append({"role": "user", "content": question})
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=chat_history,
        temperature=0.85
    )
    return response.choices[0].message.content.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ì±… ì§ˆë¬¸ ë‹µë³€ í•¨ìˆ˜
def policy_rag_answer(question, chat_history=None):
    if chat_history is None:
        chat_history = []
    policy_vector_path = os.path.join(BASE_DIR, "vectorstores", "policy_index")
    vectordb = FAISS.load_local(
        policy_vector_path, OpenAIEmbeddings(), allow_dangerous_deserialization=True
    )
    retriever = vectordb.as_retriever(search_kwargs={"k": 5})
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    from langchain.memory import ConversationBufferMemory
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    from langchain.chains import ConversationalRetrievalChain
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        memory=memory,
    )
    result = qa_chain.invoke({
        "question": question,
        "chat_history": chat_history
    })
    return result["answer"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì •ë³´ì§ˆë¬¸ ê¸°ì¡´ í•¨ìˆ˜
def classify_question_type(question):
    if any(word in question for word in ["ê°ë…", "ì‘í™”", "ì„±ìš°", "ì œì‘ì", "ë§Œë“  ì‚¬ëŒ", "ì¸ë¬¼", "í‰ê°€", "ì—…ì "]):
        return "person"
    elif any(word in question for word in ["ì¤„ê±°ë¦¬", "ë‚´ìš©", "ë¬´ìŠ¨ ë‚´ìš©", "ì–´ë–¤ ë‚´ìš©", "ìŠ¤í† ë¦¬", "ì„¤ì •"]):
        return "story"
    elif any(word in question for word in ["vs", "ë¹„êµ", "ì–´ë–¤ê²Œ ë”", "ì¶”ì²œ"]):
        return "comparison"
    else:
        return "default"

def extract_title_from_question(question):
    q = re.sub(r"(ì¤„ê±°ë¦¬|ë‚´ìš©|ì‹œì¦Œ\d+|ê·¹ì¥íŒ|í•´ì¤˜|ì•Œë ¤ì¤˜|ì¶”ì²œ|ë°©ì˜ì¼|ì •ë³´|ë‚´ìš©ì€|ë¬´ìŠ¨|ì–´ë–¤)", "", question)
    q = re.sub(r"[^\wã„±-ã…ê°€-í£a-zA-Z ]", "", q)
    return q.strip()

def normalize(text):
    return str(text).replace(" ", "").lower().strip()

def similarity(a, b):
    return SequenceMatcher(None, a, b).ratio()

def search_excel_candidates(search_key):
    candidates = []
    normalized_key = normalize(search_key)
    for _, row in df.iterrows():
        for title_col in ["title_es", "title_romaji", "title_ko", "title_native"]:
            raw_title = row.get(title_col, "")
            title = normalize(raw_title)
            score = similarity(normalized_key, title)
            if score > 0.35:
                desc = str(row.get("description_ko", "")).strip()
                format_type = row.get("format", "UNKNOWN")
                cover_image = row.get("cover_image_l", "")
                if desc:
                    candidates.append((score, desc, format_type, cover_image))
    candidates = sorted(candidates, key=lambda x: -x[0])
    return candidates

def search_web(search_key):
    api_key = os.environ.get("SERPAPI_KEY")
    search_sites = [
        "site:namu.wiki", "site:myanimelist.net", "site:aniplus.co.kr",
        "site:ani.ch", "site:wikipedia.org", "site:news.naver.com"
    ]
    result_text = ""
    extra_keywords = ["ì‹ ì‘", "ë°©ì˜ì¼", "ê³µì‹ ë°œí‘œ", "2024", "2025", "ê°œë´‰", "ìµœì‹ ", "ì´ë²¤íŠ¸", "ë°©ì˜ ì˜ˆì •"]
    for site in search_sites:
        for extra in [""] + extra_keywords:
            query = f"{search_key} {extra} {site}".strip()
            params = {
                "q": query,
                "api_key": api_key,
                "engine": "google",
                "num": 2,
                "hl": "ko"
            }
            try:
                resp = requests.get("https://serpapi.com/search", params=params, timeout=10)
                data = resp.json()
                for item in data.get("organic_results", []):
                    title = item.get("title", "")
                    snippet = item.get("snippet", "")
                    link = item.get("link", "")
                    if any(s in link for s in [
                        "namu.wiki", "myanimelist.net", "aniplus.co.kr", "ani.ch", "wikipedia.org", "news.naver.com"
                    ]):
                        if any(k in snippet for k in extra_keywords) or any(k in title for k in extra_keywords):
                            result_text += f"ğŸ“° [{title}]({link}): {snippet}\n"
                        elif site in ["site:namu.wiki", "site:wikipedia.org", "site:myanimelist.net"]:
                            result_text += f"ğŸ“š [{title}]({link}): {snippet}\n"
            except Exception:
                continue
    return result_text if result_text else "ê³µì‹ ìœ„í‚¤/í¬í„¸/ë‰´ìŠ¤ ê¸°ì¤€ ìµœì‹  ì •ë³´ ì—†ìŒ"

def ask_gpt_full_context_v2(excel_data, web_data, question, format_type="UNKNOWN", dialog_context=None):
    format_hint = ""
    if format_type.upper() in ["MOVIE", "SPECIAL", "OVA"]:
        format_hint = f"\n\nâš ï¸ ì°¸ê³ : ì´ ì„¤ëª…ì€ ë³¸í¸ TV ì‹œë¦¬ì¦ˆê°€ ì•„ë‹ˆë¼ **{format_type} í˜•ì‹**ì„. ë³¸í¸ê³¼ ì¤„ê±°ë¦¬ë‚˜ ë¶„ìœ„ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ."

    def structure_web_summary(raw_web):
        import re
        summaries = []
        source_dict = {"ê³µì‹": [], "ìœ„í‚¤": [], "ë‰´ìŠ¤": []}
        important_patterns = [
            r"ê³µì‹", r"ë°œí‘œ", r"ë°©ì˜", r"ì‹ ì‘", r"ìµœì‹ ", r"ì œì‘", r"ë‰´ìŠ¤", r"ì´ë²¤íŠ¸", r"ì¶œì‹œ", r"ì •ë³´",
            r"(20[2-9][0-9])ë…„", r"wiki", r"ìœ„í‚¤", r"ë‚˜ë¬´ìœ„í‚¤", r"êµ¬ê¸€", r"íŠ¸ìœ„í„°", r"ê³µì‹ ì‚¬ì´íŠ¸",
            r"íŠ¹ë³„íŒ", r"PV", r"í‹°ì €", r"Blu-ray", r"OST", r"ì½œë¼ë³´"
        ]
        for line in (raw_web or "").split("\n"):
            if ":" in line:
                title, content = line.split(":", 1)
                text = f"{title} {content}".lower()
                if any(text in s for src in source_dict.values() for s in src):
                    continue
                if any(re.search(p, text) for p in important_patterns):
                    if "ê³µì‹" in text or "íŠ¸ìœ„í„°" in text or "ê³µì‹ ì‚¬ì´íŠ¸" in text:
                        source_dict["ê³µì‹"].append(f"ğŸ“Œ {title.strip()}: {content.strip()}")
                    elif "ìœ„í‚¤" in text or "ë‚˜ë¬´ìœ„í‚¤" in text:
                        source_dict["ìœ„í‚¤"].append(f"ğŸ“Œ {title.strip()}: {content.strip()}")
                    elif "ë‰´ìŠ¤" in text or "êµ¬ê¸€" in text:
                        source_dict["ë‰´ìŠ¤"].append(f"ğŸ“Œ {title.strip()}: {content.strip()}")
                    else:
                        summaries.append(f"ğŸ“Œ {title.strip()}: {content.strip()}")
        output = []
        for k, v in source_dict.items():
            if v:
                output.append(f"[{k}]\n" + "\n".join(v[:2]))
        if summaries:
            output.append("\n".join(summaries[:3]))
        return "\n\n".join(output) if output else (raw_web or "")

    web_summary = structure_web_summary(web_data or "")
    chat_history = [{"role": "system", "content": system_prompt}]
    if dialog_context:
        chat_history += dialog_context
    chat_history.append({"role": "user", "content": f"""
ğŸ“‹ ì§ˆë¬¸: {question}

ğŸŒ ì›¹ ê²€ìƒ‰ ìš”ì•½:
{web_summary or 'ì›¹ ì •ë³´ ì—†ìŒ'}

ğŸ“– ì—‘ì…€ ì„¤ëª…:
{excel_data or 'ì—‘ì…€ ì •ë³´ ì—†ìŒ'}
{format_hint}

â€» ì•„ë˜ context(ì—‘ì…€/ì›¹)ëŠ” ì°¸ê³ ë§Œ í•´ë„ ë˜ê³ ,
ë‚´ì¥ ì§€ì‹(2023ë…„ê¹Œì§€ í•™ìŠµ ë°ì´í„°, ê³µì‹ ì •ë³´ ë“±)ì´ ë” ì •í™•í•˜ë©´ ê·¸ê±¸ ìš°ì„ ìœ¼ë¡œ í™œìš©í•´ì„œ ë‹µë³€í•´.
ë‘˜ì´ ì¶©ëŒí•˜ë©´ ê³µì‹/ì •í™•ì„±/ìµœì‹ ì„±ì„ ë°˜ë“œì‹œ ìš°ì„ ì‹œ.
ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ë¶ˆí™•ì‹¤í•˜ë©´ â€œì •ë³´ ì—†ìŒâ€, â€œê³µì‹ ìœ„í‚¤/í¬í„¸ ì°¸ê³ â€ ë“±ìœ¼ë¡œ ëª…í™•í•˜ê²Œ ì•ˆë‚´í•´.
"""})

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=chat_history,
        temperature=0.7
    )

    def remove_undefined_items(text):
        return re.sub(r'^.*[\'"\[]?ë¯¸ì •[\]"\d\s\-:)]?.*\n?', '', text, flags=re.MULTILINE | re.IGNORECASE)

    def remove_placeholder_titles(text):
        return re.sub(r'^.*(ì‘í’ˆëª…\d+|ì„¤ëª…\d+).*\n?', '', text, flags=re.MULTILINE)

    raw_answer = response.choices[0].message.content.strip()
    clean_answer = remove_undefined_items(raw_answer)
    clean_answer = remove_placeholder_titles(clean_answer)
    return clean_answer